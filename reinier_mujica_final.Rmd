---
title: "Trabajo Final de Aprendizaje estadístico"
author: "Reinier César Mujica Hernández"
date: "29 de diciembre de 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,  warning=FALSE, message=FALSE, comment = NA)
library(knitr)
```

### Descripción del dataset
El dataset seleccionado es [Health Insurance and Hours Worked By Wives](https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/HI.html), el cual contiene información acerca de la cobertura medica y la cantidad de horas semanales trabajadas por las mujeres casadas en Estados Unidos. La información que contiene el dataset fue recopilada en el año 1993, contiene 22272 observaciones con 13 variables. El dataset no contiene valores NA. En este análisis de los datos trataremos de predecir la variable **whrswk** que es la cantidad de horas trabajadas a la semana por las esposas. La métrica usada en cada modelo será el error cuadrático medio (Mean Squared Error MSE).


### Limpiamos el workspace de R
```{r}
rm(list=ls())
setwd("d:/MADM/Analisis/statics_final_task/")
```

### Cargamos los datos
```{r}
datos <- read.csv2('HI.csv', dec=".", sep = ",")

# eliminamos la primera columna que es solo un contador de filas
datos["X"] = NULL

# eliminamos posibles valores NA dentro del dataset
datos = na.omit(datos)
attach(datos)
```

### Resumen del dataset
A continuación se muestra un resumen del dataset extraído de la documentación del mismo.
El dataset contiene las siguientes variables:
```{r}
colnames(datos)
```
El significado de cada una de las variables se mustra a continuación:

**whrswk** hours worked per week by wife

**hhi** wife covered by husband's HI

**whi** wife has HI thru her job

**hhi2** husband has HI thru own job ?

**education** a factor with levels, "<9years", "9-11years", "12years", "13-15years", "16years", ">16years"

**race** one of white, black, other

**hispanic** hispanic ?

**experience** years of potential work experience

**kidslt6** number of kids under age of 6

**kids618** number of kids 6–18 years old

**husby** husband's income in thousands of dollars

**region** one of other, northcentral, south, west

**wght** sampling weight

Como se puede observar tenemos variables categóricas y continuas.

### Dividimos el dataset en TRAIN y TEST
Ahora dividimos el dataset en dos conjuntos (Train y Test) con un ratio de 0.7, hemos fijado una constante **seed** que contendrá la semilla que se va a utilizar en todo el análisis.

```{r}
seed = 1991
set.seed(seed)

# generamos los datos de TRAIN con el 70% del dataset
train.size = round(dim(datos)[1] * 0.7)
train.indexs = sample(1:dim(datos)[1], train.size)
train.data = datos[train.indexs, ]

test.indexs = -train.indexs
test.data = datos[test.indexs, ]
test.size = dim(test.data)[1]

```

### Realizamos algunas Visualizaciones
Ahora realizaremos algunas visualizaciones interesantes para entender los datos. Haremos uso de la libreria **ggplot**.

Aqui podemos ver la distribución de muestras por region, aunque no es exactamente la misma en cada region podemos ver que es bastante balanceado.
```{r}
library(ggplot2)
ggplot(data = datos) +
  geom_bar(mapping = aes(x = region))

```

Sin embargo no sucede lo mismo con la distribución de las muestras por raza, donde casi todas se concentran en un solo valor.
```{r}
ggplot(data = datos) +
  geom_bar(mapping = aes(x = race))

```

Con respecto a la variable **hispanic** sucede igual, todas las muestras se concentran en un solo valor.

```{r}
ggplot(data = datos) +
  geom_bar(mapping = aes(x = hispanic))

```


### Aplicamos un MCO a los datos 
Para tener una referencia del error de prueba al realizar predicciones en el dataset vamos a ajustar un modelo de mínimos cuadrados ordinarios (MCO) con todas las variables explicativas en el conjunto de entrenamiento, el error de prueba obtenido lo guardaremos para futuras comparaciones con métodos más avanzados.

```{r}
set.seed(seed)
mco.fit = glm(whrswk ~ ., data = train.data)
mco.pred = predict(mco.fit, newdata = test.data)

error.mco <- mean((test.data[, "whrswk"] - mco.pred) ^ 2)

summary(mco.fit)
```

Aplicando el MCO obtenemos el error de prueba `r error.mco`.

### Aplicamos métodos mas avanzados

#### Usando Random Forest
A continuación usaremos el método de Random Forest en los datos de entrenamiento usaremos un valor de **ntree** que nos permita realizar las simulaciones sin consumir una cantidad excesiva de tiempo.

```{r}
library(randomForest)
library(MASS)
set.seed(seed)
Ntree = 500

rf.fit=randomForest(whrswk~.,data=train.data, ntree = Ntree)
rf.fit
rf.pred = predict(rf.fit, test.data)
error.rf = with(test.data, mean((whrswk - rf.pred)^2))

```
Como resultado obtenemos se usan `r rf.fit$mtry` (**mtry**) variables para cada partición y el error obtenido en los datos de prueba es `r error.rf`, el cual es menor que en el MCO. 

Como el número de variables independientes es `r dim(datos)[2] - 1`, calcularemos todos los `r dim(datos)[2] - 1` valores de **mtry**.

```{r}
set.seed(seed)
Ntree = 200

dimension = dim(datos)[2] - 1
oob.error = double(dimension)
error.rf.full =double(dimension)

for(mtry in 1:dimension) {
  fit = randomForest(whrswk~., data = train.data, mtry = mtry, ntree = Ntree)
  oob.error[mtry] = fit$mse[Ntree]
  pred = predict(fit, test.data)
  error.rf.full[mtry] = with(test.data, mean((whrswk - pred) ^ 2))
  message(mtry)
}

matplot(1:mtry, cbind(error.rf.full, oob.error), pch=19, col=c("red", "blue"), type="b", ylab="Mean Squared Error")
legend("topright",legend=c("Test","OOB"),pch=19,col=c("red","blue"))
```

Como se puede apreciar en el gráfico el error mas pequeño es cuando se usa mtry = `r which(min(error.rf.full) == error.rf.full)`, este es de `r min(error.rf.full)`.

```{r}
# nos quedamos con el menor error de los Random Forests
error.rf = min(c(error.rf, min(error.rf.full)))
```


#### BOOSTING
Ahora usaremos BOOSTING como método mas avanzado y esperamos obtener un error aun menor.

```{r}
library(gbm)
Ntree = 1000 
set.seed(seed)

boosting.fit = gbm(whrswk~., data=train.data, distribution = "gaussian" , n.trees = Ntree, shrinkage=0.01, interaction.depth = 4)
summary(boosting.fit)
```

En el gráfico anterior podemos observar la influencia de cada una de las variables en el modelo de boosting.

Luego de entrenar el modelo en los datos de entrenamiento hacemos la predicción en los datos de prueba.

```{r}
n.trees=seq(from=100, to=Ntree, by=100)
boosting.pred = predict(boosting.fit, newdata = test.data, n.trees=n.trees)

error.boosting = with(test.data, apply((boosting.pred - whrswk) ^ 2, 2, mean))

plot(n.trees, error.boosting, pch=19, ylab="Mean Squared Error", xlab="# Trees",main="Boosting Test Error")

error.boosting = min(error.boosting)
```
El menor error de predicción usando el método de **Boosting** es `r error.boosting`.

Ahora aplicaremos validación cruzada con Boosting para intentar mejorar el resultado anterior.

```{r}
CV = 5
Ntree = 1000
set.seed(seed)

boosting.cv = gbm(whrswk~., data=train.data, distribution = "gaussian", n.trees=Ntree, cv.folds = CV, shrinkage = 0.01, interaction.depth = 4)

best_iter <- gbm.perf(boosting.cv, method="cv")
```

La validación cruzada nos da como resultado que el número óptimo de iteraciones es `r best_iter`.

A continuación se observa la influencia de las variables en el modelo de boosting con `r best_iter` iteraciones.

```{r}
summary(boosting.cv, n.trees = best_iter) 
```

Ahora vamos a realizar la predicción en los datos de prueba.

```{r}

n.trees = seq(from=100, to=best_iter, by=100)
predmat = predict(boosting.fit, newdata = test.data, n.trees = n.trees)

error.boosting_cv = with(test.data, apply((predmat - whrswk) ^ 2, 2, mean))
plot(n.trees, error.boosting_cv, pch=19, ylab = "Mean Squared Error", xlab = "# Trees", main = "Boosting Test Error")
error.boosting_cv = min(error.boosting_cv)
``` 

Como podemos observar en el gráfico anterior, luego de aplicar la validación cruzada con Boosting el mínimo error de prueba es `r error.boosting_cv`.

#### BOOSTING CON CARET
Ahora usaremos la libreria **caret** para hacer una búsqueda de los mejores párametros para el método de BOOSTING.
```{r}
library(caret)
set.seed(seed)
Ntree = 2000

gbmGrid <- expand.grid(interaction.depth = c(1, 3, 4, 5, 7),
                        n.trees = seq(500,Ntree,500),
                        shrinkage = seq(.005, .05,.005),
                        n.minobsinnode = 10)

fitControl <- trainControl(method = 'cv', number = 5, summaryFunction = defaultSummary)

out <- capture.output(gradientBoosting.fit <- train(whrswk~., data = train.data, method = 'gbm', trControl=fitControl, tuneGrid=gbmGrid, metric='RMSE'))

plot(gradientBoosting.fit)

```
Después de realizar la búsqueda de los mejores parámetros nos queda que son los siguientes:

```{r}
kable(gradientBoosting.fit$bestTune)
```

```{r}
res <- gradientBoosting.fit$results
RMSE <- subset(res[5])
```
El mínimo error de entrenamiento nos da como resultado `r min(RMSE)^2`.

Ahora procedemos a utilizar el modelo para realizar la predicción el los datos de prueba.
```{r}
gradientBoosting.pred <- predict(gradientBoosting.fit, test.data)
error.gradientBoosting = (mean((gradientBoosting.pred - test.data$whrswk) ^ 2))
```

El error en los datos de prueba nos queda `r error.gradientBoosting`.

### Comparamos y gráficamos los resultados
Ahora vamos a conformar una tabla con los mínimos errores de prueba obtenidos por los métodos anteriores.
```{r}
results <- matrix(NA, nrow = 1, ncol = 5)
colnames(results) <- c("MCO","Random Forests", "Boosting", "Boosting con 5-CV", "Gradient Boosting")
rownames(results) <- c("Error")
results <- as.table(results)

results["Error", "MCO"] = error.mco
results["Error", "Random Forests"] = error.rf
results["Error", "Boosting"] = error.boosting
results["Error", "Boosting con 5-CV"] = error.boosting_cv
results["Error", "Gradient Boosting"] = error.gradientBoosting

kable(results)

```

Como podemos observar en la tabla el modelo que menor error de prueba presenta es el **Gradient Boosting** con un `r error.gradientBoosting`, para realizar la predicción en este dataset recomendamos este modelo con los parametros siguientes:
```{r}
kable(gradientBoosting.fit$bestTune)
```
